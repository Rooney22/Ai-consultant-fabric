{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_community.document_loaders import CSVLoader, PyPDFLoader\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Milvus\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_gigachat import GigaChat\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "def create_milvus_langchain_agent(agent_name: str, system_prompt: str, file_paths: list):\n",
    "    # Загрузка и обработка данных из файлов\n",
    "    documents = []\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)  # Разбиение текста на чанки\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        if file_path.endswith('.pdf'):\n",
    "            loader = PyPDFLoader(file_path)\n",
    "            pdf_docs = loader.load()\n",
    "            split_docs = text_splitter.split_documents(pdf_docs)\n",
    "            documents.extend(split_docs)\n",
    "        else:\n",
    "            raise ValueError(\"Неподдерживаемый формат файла. Поддерживаются только CSV, Excel и PDF файлы.\")\n",
    "\n",
    "    # Инициализация модели для эмбеддингов\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='deepvk/USER-bge-m3', cache_folder='../cache/embedding/')\n",
    "\n",
    "    # Создание векторной базы данных Milvus\n",
    "    vector_db = Milvus.from_documents(\n",
    "        documents,\n",
    "        embeddings,\n",
    "        connection_args={\"host\": \"localhost\", \"port\": \"19530\"},\n",
    "        collection_name=agent_name\n",
    "    )\n",
    "\n",
    "    # Создание BM25Retriever\n",
    "    bm25_retriever = BM25Retriever.from_documents(documents, k=3)  # k — количество возвращаемых документов\n",
    "\n",
    "    # Создание EnsembleRetriever\n",
    "    ensemble_retriever = EnsembleRetriever(\n",
    "        retrievers=[vector_db.as_retriever(), bm25_retriever],\n",
    "        weights=[0.7, 0.3]  # Веса для каждого ретривера (70% для Milvus, 30% для BM25)\n",
    "    )\n",
    "\n",
    "    # Создание цепочки Langchain\n",
    "    template = system_prompt + \"\\n\\nКонтекст:\\n{context}\\n\\nВопрос: {question}\\n\\nОтвет:\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # Инициализация GigaChat LLM\n",
    "    llm = GigaChat(credentials=\"your_gigachat_credentials_here\")\n",
    "\n",
    "    # Создание цепочки\n",
    "    chain = (\n",
    "        {\"context\": ensemble_retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    return chain\n",
    "\n",
    "# Пример использования функции\n",
    "agent_name = \"RUTUBE_Assistant\"\n",
    "system_prompt = \"Ты интеллектуальный помощник компании RUTUBE. Отвечай на вопросы, используя предоставленный контекст.\"\n",
    "file_paths = [\"../data/01_База_знаний.xlsx\", \"../data/02_Реальные_кейсы.xlsx\", \"../data/some_document.pdf\"]\n",
    "\n",
    "chain = create_milvus_langchain_agent(agent_name, system_prompt, file_paths)\n",
    "\n",
    "# Тестирование цепочки\n",
    "response = chain.invoke(\"Как подключить монетизацию на RUTUBE?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Milvus\n",
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_gigachat import GigaChat\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "def create_chain_from_existing_collection(system_prompt: str, collection_name: str, bm25_documents: list):\n",
    "    \"\"\"\n",
    "    Создает цепочку (chain) на основе существующей коллекции Milvus и BM25Retriever.\n",
    "\n",
    "    :param system_prompt: Системный промпт для LLM.\n",
    "    :param collection_name: Имя существующей коллекции Milvus.\n",
    "    :param bm25_documents: Документы для BM25Retriever (список объектов Document).\n",
    "    :return: Цепочка (chain) для генерации ответов.\n",
    "    \"\"\"\n",
    "    # Инициализация модели для эмбеддингов\n",
    "    embeddings = HuggingFaceEmbeddings(model_name='deepvk/USER-bge-m3', cache_folder='../cache/embedding/')\n",
    "\n",
    "    # Подключение к существующей коллекции Milvus\n",
    "    vector_db = Milvus(\n",
    "        embedding_function=embeddings,\n",
    "        collection_name=collection_name,\n",
    "        connection_args={\"host\": \"localhost\", \"port\": \"19530\"}\n",
    "    )\n",
    "\n",
    "    # Создание BM25Retriever на основе предоставленных документов\n",
    "    bm25_retriever = BM25Retriever.from_documents(bm25_documents, k=3)  # k — количество возвращаемых документов\n",
    "\n",
    "    # Создание EnsembleRetriever\n",
    "    ensemble_retriever = EnsembleRetriever(\n",
    "        retrievers=[vector_db.as_retriever(), bm25_retriever],\n",
    "        weights=[0.7, 0.3]  # Веса для каждого ретривера (70% для Milvus, 30% для BM25)\n",
    "    )\n",
    "\n",
    "    # Создание цепочки Langchain\n",
    "    template = system_prompt + \"\\n\\nКонтекст:\\n{context}\\n\\nВопрос: {question}\\n\\nОтвет:\"\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "    # Инициализация GigaChat LLM\n",
    "    llm = GigaChat(credentials=\"your_gigachat_credentials_here\")\n",
    "\n",
    "    # Создание цепочки\n",
    "    chain = (\n",
    "        {\"context\": ensemble_retriever, \"question\": RunnablePassthrough()}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    return chain\n",
    "\n",
    "# Пример использования функции\n",
    "system_prompt = \"Ты интеллектуальный помощник компании RUTUBE. Отвечай на вопросы, используя предоставленный контекст.\"\n",
    "collection_name = \"RUTUBE_Assistant\"  # Имя существующей коллекции Milvus\n",
    "\n",
    "# Предположим, что у нас уже есть документы для BM25Retriever\n",
    "bm25_documents = [\n",
    "    Document(page_content=\"Вопрос: Как подключить монетизацию?\\nОтвет: Для подключения монетизации нужно...\", metadata={\"source\": \"data.csv\"}),\n",
    "    Document(page_content=\"Вопрос: Что нельзя публиковать на RUTUBE?\\nОтвет: Чужой контент без разрешения...\", metadata={\"source\": \"data.csv\"}),\n",
    "]\n",
    "\n",
    "# Создание цепочки\n",
    "chain = create_chain_from_existing_collection(system_prompt, collection_name, bm25_documents)\n",
    "\n",
    "# Тестирование цепочки\n",
    "response = chain.invoke(\"Как подключить монетизацию на RUTUBE?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
